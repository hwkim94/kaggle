{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkling Emoticana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflowonspark as TFOS\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import nested_scopes\n",
    "from __future__ import print_function\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflowonspark import dfutil\n",
    "from tensorflowonspark import TFNode\n",
    "from tensorflowonspark.pipeline import TFEstimator, TFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-31-96.ap-northeast-2.compute.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br> <br></br> <br></br> <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding(data, num=8) :\n",
    "    return np.eye(num)[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting(train, valid, test, size=1025, num=276) :\n",
    "    result = []\n",
    "    half = int(num/2)\n",
    "    \n",
    "    for dataset in [train, valid, test] :\n",
    "        if not dataset :\n",
    "            continue\n",
    "            \n",
    "        zero = np.zeros([len(dataset), size, num])\n",
    "        emotion_lst = []\n",
    "\n",
    "        idx = 0\n",
    "        for spectrogram, emotion in dataset:\n",
    "            mid = int(spectrogram.shape[1]/2)\n",
    "            zero[idx, :, 0:len(spectrogram[0])] = spectrogram[:, mid-half:mid+half]\n",
    "            emotion_lst.append(emotion-1)\n",
    "            idx += 1\n",
    "            \n",
    "        result.append((zero, emotion_lst))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_data(path) :\n",
    "    file_lst = os.listdir(path)\n",
    "    random.shuffle(file_lst)\n",
    "    \n",
    "    train = []\n",
    "    valid = []\n",
    "    test = []\n",
    "    \n",
    "    for file in file_lst :\n",
    "        try : \n",
    "            y, sr = librosa.load(path+file)\n",
    "            emotion = int(file.split(\"-\")[2])\n",
    "            actor = int(file.split(\"-\")[6].split(\".\")[0])\n",
    "        \n",
    "            melspectrogram = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "        \n",
    "            if actor in [1,2] :\n",
    "                valid.append((melspectrogram, emotion))\n",
    "            elif actor in [3,4] :\n",
    "                test.append((melspectrogram, emotion))\n",
    "            else :\n",
    "                train.append((melspectrogram, emotion))\n",
    "                \n",
    "        except :\n",
    "            pass\n",
    "    \n",
    "    return file_lst, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_test_data(path) :\n",
    "    file_lst = os.listdir(path)\n",
    "    random.shuffle(file_lst)\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    for file in file_lst :\n",
    "        try : \n",
    "            y, sr = librosa.load(path+file)\n",
    "            emotion = int(file.split(\"-\")[2])\n",
    "            actor = int(file.split(\"-\")[6].split(\".\")[0])\n",
    "        \n",
    "            melspectrogram = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "            test.append((melspectrogram, emotion))\n",
    "\n",
    "                \n",
    "        except :\n",
    "            pass\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(df):\n",
    "    # Convert from dict of named arrays to two numpy arrays of the proper type\n",
    "    train_data = np.array(list(df.select('image').toPandas()['image'])).reshape([-1, 128, 126, 1])\n",
    "    train_label = np.array(list(df.select('label').toPandas()['label'])).reshape([-1, 8])\n",
    "        \n",
    "    return (train_data, train_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(worker_num, arg):\n",
    "    print(\"{0}: {1}\".format(worker_num, arg))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_df(data, label) :\n",
    "    data_rdd = sc.parallelize(data.reshape([-1, 128, 126]).tolist())\n",
    "    label_rdd = sc.parallelize(label.reshape([-1, 8]).tolist())\n",
    "    \n",
    "    pair = data_rdd.zip(label_rdd)\n",
    "    df = spark.createDataFrame(pair, ['image', 'label'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br> <br></br> <br></br> <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN() :\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def convolution(self, X_input, filters, kernel_size, strides, name, padding=\"SAME\") :\n",
    "        with tf.variable_scope(name) :\n",
    "            bn = tf.layers.batch_normalization(X_input)\n",
    "            conv = tf.layers.conv2d(bn, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            relu = tf.nn.leaky_relu(conv)\n",
    "            \n",
    "            return relu\n",
    "            \n",
    "    def build(self) :\n",
    "        with tf.variable_scope(self.name) :\n",
    "            ### Input\n",
    "            #input : 128x126x1\n",
    "            #output : 8\n",
    "            self.X = tf.placeholder(tf.float32, [None, 128, 126, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 8])\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "            self.learning_rate = tf.placeholder(tf.float32)\n",
    "            print(self.X.shape)\n",
    "            \n",
    "        ### Input Layer\n",
    "        #input : 128x126x1\n",
    "        #output : 32x31x8\n",
    "        conv1 = self.convolution(self.X, 8, [3,3], 2, \"conv1\")\n",
    "        pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2,2], strides=2, name=\"pool1\")\n",
    "        print(conv1.shape)\n",
    "        print(pool1.shape)\n",
    "\n",
    "        ### Hidden Layer1\n",
    "        #input : 32x31x8\n",
    "        #output : 32x31x16\n",
    "        conv2 = self.convolution(conv1, 16, [3,3], 1, \"conv2\")\n",
    "        print(conv2.shape)\n",
    "            \n",
    "        ### Hidden Layer2\n",
    "        #input : 32x31x16\n",
    "        #output : 32x31x32\n",
    "        conv3 = self.convolution(conv2, 32, [3,3], 1, \"conv3\")\n",
    "        print(conv3.shape)\n",
    "            \n",
    "        ### Pooling Layer2\n",
    "        #input : 32x31x32\n",
    "        #output : 16x15x32\n",
    "        pool2 = tf.layers.max_pooling2d(conv3, pool_size=[2,2], strides=2, name=\"pool2\")\n",
    "        print(pool2.shape)\n",
    "            \n",
    "        ### Hidden Layer3\n",
    "        #input : 16x15x32\n",
    "        #output : 16x15x64\n",
    "        conv4 = self.convolution(pool2, 64, [3,3], 1, \"conv4\")\n",
    "        print(conv4.shape)\n",
    "        \n",
    "        ### Hidden Layer4\n",
    "        #input : 16x15x64\n",
    "        #output : 16x15x128\n",
    "        conv5 = self.convolution(conv4, 128, [3,3], 1, \"conv5\")\n",
    "        print(conv5.shape)\n",
    "        \n",
    "        ### Pooling Layer3\n",
    "        #input : 16x15x128\n",
    "        #output : 8x7x128\n",
    "        pool3 = tf.layers.max_pooling2d(conv5, pool_size=[2,2], strides=2, name=\"pool3\")\n",
    "        print(pool3.shape)\n",
    "        \n",
    "        ### Hidden Layer5\n",
    "        #input : 8x7x128\n",
    "        #output : 8x7x32\n",
    "        conv6 = self.convolution(pool3, 32, [1,1], 1, \"conv6\")\n",
    "        print(conv6.shape)\n",
    "        \n",
    "        with tf.variable_scope(\"global_avg_pooling\") :\n",
    "            ### global avg pooling\n",
    "            #input : 8x7x32\n",
    "            #output : 1x1x32\n",
    "            global_avg_pooling = tf.reduce_mean(conv6, [1, 2], keep_dims=True)\n",
    "            print(global_avg_pooling.shape)\n",
    "        \n",
    "        with tf.variable_scope(\"fully_connected\") :\n",
    "            ###Output Layer\n",
    "            #input : 1x1x32\n",
    "            #ouput : 8\n",
    "            shape = global_avg_pooling.get_shape().as_list()\n",
    "            dimension = shape[1] * shape[2] * shape[3]\n",
    "            self.flat = tf.reshape(global_avg_pooling, shape=[-1, dimension])\n",
    "\n",
    "            fc = tf.layers.dense(inputs=self.flat, units=8, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.logits = fc\n",
    "\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))     \n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    def set_sess(self, sess) :\n",
    "        self.sess = sess\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        feed_dict={self.X: x_test, self.training: training}\n",
    "        \n",
    "        return self.sess.run(self.logits, feed_dict=feed_dict)\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        feed_dict={self.X: x_test,self.Y: y_test, self.training: training}\n",
    "        \n",
    "        return self.sess.run(self.accuracy, feed_dict=feed_dict)\n",
    "\n",
    "    def train(self, x_data, y_data, learning_rate, training=True):\n",
    "        feed_dict={self.X: x_data, self.Y: y_data, self.learning_rate: learning_rate, self.training: training}\n",
    "        \n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict=feed_dict)\n",
    "    \n",
    "    def evaluate(self, X_input, Y_input, batch_size=None, training=False):\n",
    "        N = X_input.shape[0]\n",
    "            \n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "            \n",
    "        for i in range(0, N, batch_size):\n",
    "            X_batch = X_input[i:i + batch_size]\n",
    "            Y_batch = Y_input[i:i + batch_size]\n",
    "                \n",
    "            feed_dict = {self.X: X_batch, self.Y: Y_batch, self.training: training}\n",
    "                \n",
    "            loss = self.cost\n",
    "            accuracy = self.accuracy\n",
    "                \n",
    "            step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed_dict)\n",
    "                \n",
    "            total_loss += step_loss * X_batch.shape[0]\n",
    "            total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "        total_loss /= N\n",
    "        total_acc /= N\n",
    "            \n",
    "        return total_loss, total_acc\n",
    "    \n",
    "    def save(self, ver) :\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(self.sess, \"CNN_\" + str(ver) + \".ckpt\")\n",
    "        \n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br> <br></br> <br></br> <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_executors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Conference_2018_1/CNN_ckpt/ver_1\n",
      "/home/ubuntu/Conference_2018_1/CNN_tfos/ver_1\n",
      "/home/ubuntu/Conference_2018_1/CNN_result/ver_1\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "model_dir = os.sep.join([cwd, \"CNN_ckpt/ver_1\"])       # path to TensorFlow model/checkpoint\n",
    "export_dir = os.sep.join([cwd, \"CNN_tfos/ver_1\"])      # path to TensorFlow saved_model export\n",
    "output = os.sep.join([cwd, \"CNN_result/ver_1\"])        # path to output of inferencing\n",
    "data_dir = os.sep.join([cwd, \"data/wav\"]) \n",
    "\n",
    "print(model_dir)\n",
    "print(export_dir)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--batch_size\", help=\"number of records per batch\", type=int, default=40)\n",
    "parser.add_argument(\"--epochs\", help=\"number of epochs\", type=int, default=50)\n",
    "parser.add_argument(\"--model_dir\", help=\"HDFS path to save/load model during train/inference\", type=str)\n",
    "parser.add_argument(\"--export_dir\", help=\"HDFS path to export saved_model\", type=str)\n",
    "parser.add_argument(\"--cluster_size\", help=\"number of nodes in the cluster\", type=int, default=num_executors)\n",
    "parser.add_argument(\"--num_ps\", help=\"number of PS nodes in cluster\", type=int, default=1)\n",
    "parser.add_argument(\"--protocol\", help=\"Tensorflow network protocol (grpc|rdma)\", default=\"grpc\")\n",
    "parser.add_argument(\"--steps\", help=\"maximum number of steps\", type=int, default=1000)\n",
    "parser.add_argument(\"--tensorboard\", help=\"launch tensorboard process\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"--format\", help=\"format: wav\", default=\"wav\")\n",
    "parser.add_argument(\"--datas\", help=\"HDFS path to MNIST data in parallelized format\")\n",
    "parser.add_argument(\"--output\", help=\"HDFS path to save test/inference output\", default=\"predictions\")\n",
    "\n",
    "parser.add_argument(\"--train\", help=\"train a model using Estimator\", action=\"store_true\")\n",
    "parser.add_argument(\"--inference_mode\", help=\"type of inferencing (none|checkpoint|signature|direct)\", choices=[\"none\",\"signature\",\"direct\",\"checkpoint\"], default=\"none\")\n",
    "parser.add_argument(\"--inference_output\", help=\"output type for inferencing (predictions|features)\", choices=[\"predictions\",\"features\"], default=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\"--model_dir\", model_dir, \\\n",
    "                          \"--export_dir\", export_dir, \\\n",
    "                          \"--output\", output, \\\n",
    "                          \"--datas\", data_dir, \\\n",
    "                          \"--train\", \\\n",
    "                          \"--inference_mode\", \"checkpoint\", \\\n",
    "                          \"--inference_output\", \"predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br> <br></br> <br></br> <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TFoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_funtion(args, ctx):\n",
    "    \n",
    "    # Delay PS nodes a bit, since workers seem to reserve GPUs more quickly/reliably (w/o conflict)\n",
    "    if job_name == \"ps\":\n",
    "        time.sleep((worker_num + 1) * 5)\n",
    "        \n",
    "    # Get TF cluster and server instances\n",
    "    cluster, server = TFNode.start_cluster_server(ctx, 0, args.protocol == 'rdma')\n",
    "\n",
    "    worker_num = ctx.worker_num\n",
    "    job_name = ctx.job_name\n",
    "    task_index = ctx.task_index\n",
    "    \n",
    "    height = 128\n",
    "    width = 126\n",
    "    batch_size = args.batch_size\n",
    "    \n",
    "    if job_name == \"ps\":\n",
    "        server.join()\n",
    "    elif job_name == \"worker\":\n",
    "\n",
    "        # Assigns ops to the local worker by default.\n",
    "        with tf.device(tf.train.replica_device_setter(worker_device=\"/job:worker/task:%d\" % task_index, cluster=cluster)):\n",
    "            model = CNN(\"CNN\")\n",
    "            global_step = tf.Variable(0)\n",
    "            \n",
    "            logit = model.logits\n",
    "            loss = model.cost\n",
    "            optimizer = model.optimizer\n",
    "            accuracy = model.accuracy\n",
    "            \n",
    "            tf.summary.scalar(\"loss\", loss)\n",
    "            tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "            summary_op = tf.summary.merge_all()\n",
    "            initializer = tf.global_variables_initializer()\n",
    "\n",
    "        # Create a \"supervisor\", which oversees the training process and stores model state into HDFS\n",
    "        logdir = TFNode.hdfs_path(ctx, args.model_dir)\n",
    "        summary_writer = tf.summary.FileWriter(\"tensorboard_%d\" % (worker_num), graph=tf.get_default_graph())\n",
    "        print(\"tensorflow model path: {0}\".format(logdir))\n",
    "\n",
    "        sv = tf.train.Supervisor(is_chief=(task_index == 0),\n",
    "                                 logdir=logdir,\n",
    "                                 init_op=initializer,\n",
    "                                 summary_op=None,\n",
    "                                 saver=saver,\n",
    "                                 global_step=global_step,\n",
    "                                 stop_grace_secs=300,\n",
    "                                 save_model_secs=5)\n",
    "\n",
    "        # The supervisor takes care of session initialization, restoring from\n",
    "        # a checkpoint, and closing when done or an error occurs.\n",
    "        with sv.managed_session(server.target) as sess:\n",
    "            print(\"{0} session ready\".format(datetime.now().isoformat()))\n",
    "\n",
    "            step = 0\n",
    "            tf_feed = TFNode.DataFeed(ctx.mgr, input_mapping=args.input_mapping)\n",
    "\n",
    "            while not sv.should_stop() and not tf_feed.should_stop() and step < args.steps:\n",
    "                batch_xs, batch_ys = get_batch_data(tf_feed.next_batch(batch_size))\n",
    "                 \n",
    "                feed_dict1 = {mode.X: batch_xs, model.Y: batch_ys, model.learning_rate: 0.008, self.training:True}\n",
    "                feed_dict2 = {mode.X: batch_xs, model.Y: batch_ys, model.learning_rate: 0.008, self.training:False}\n",
    "                \n",
    "                if len(batch_xs) > 0:\n",
    "                    _, summary, step = sess.run([optimizer, summary_op, global_step], feed_dict=feed_dict1)\n",
    "\n",
    "                    if (step % 20 == 0):\n",
    "                        print(\"{0} step: {1} accuracy: {2}\".format(datetime.now().isoformat(), step, sess.run(accuracy, feed_dict = feed_dict2)))\n",
    "\n",
    "                    if sv.is_chief:\n",
    "                        summary_writer.add_summary(summary, step)\n",
    "\n",
    "            if sv.should_stop() or step >= args.steps:\n",
    "                tf_feed.terminate()\n",
    "\n",
    "            if sv.is_chief and args.export_dir:\n",
    "                print(\"{0} exporting saved_model to: {1}\".format(datetime.now().isoformat(), args.export_dir))\n",
    "\n",
    "                signatures = {\n",
    "                  tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: {\n",
    "                    'inputs': {'image': self.X},\n",
    "                    'outputs': {'prediction': logit},\n",
    "                    'method_name': tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "                  },\n",
    "                  'featurize': {\n",
    "                    'inputs': {'image': model.X},\n",
    "                    'outputs': {'features': model.flat},\n",
    "                    'method_name': 'featurize'\n",
    "                  }\n",
    "                }\n",
    "                TFNode.export_saved_model(sess,\n",
    "                                          args.export_dir,\n",
    "                                          tf.saved_model.tag_constants.SERVING,\n",
    "                                          signatures)\n",
    "                \n",
    "            else:\n",
    "                while not sv.should_stop():\n",
    "                    print(\"Waiting for chief\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "        print(\"{0} stopping supervisor\".format(datetime.now().isoformat()))\n",
    "        sv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.format == \"wav\" and args.train :\n",
    "    file_lst, train, valid, test = load_wav_data(args.data)\n",
    "    cut_train, cut_valid, cut_test = cutting(train, valid, test, size =128 , num=126)\n",
    "\n",
    "    train_data = cut_train[0].reshape([-1, 128, 126, 1])\n",
    "    train_label = onehot_encoding(cut_train[1])\n",
    "    \n",
    "    test_data = cut_test[0].reshape([-1, 128, 126, 1])\n",
    "    test_label = onehot_encoding(cut_test[1])\n",
    " \n",
    "    df_train = np_to_df(train_data, train_label)\n",
    "    df_test = np_to_df(test_data, testlabel)\n",
    "    \n",
    "elif args.format == \"wav\" and (not args.train) :\n",
    "    test = load_wav_test_data(args.data)\n",
    "    cut_test = cutting_test([], [], test, size=128, num=126)\n",
    "    \n",
    "    test_data = cut_train[0].reshape([-1, 128, 126, 1])\n",
    "    test_label = onehot_encoding(cut_train[1])\n",
    "    \n",
    "    df = np_to_df(test_data, test_label)\n",
    "    \n",
    "else:\n",
    "    raise Exception(\"Unsupported format: {}\".format(args.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.train:\n",
    "    tf_args = { 'initial_learning_rate': 0.01, 'num_epochs_per_decay': 2.0, 'learning_rate_decay_factor': 0.95 }\n",
    "    estimator = TFEstimator(CNN_function, tf_args) \\\n",
    "          .setInputMapping({'image':'image', 'label':'label'}) \\\n",
    "          .setModelDir(args.model_dir) \\\n",
    "          .setExportDir(args.export_dir) \\\n",
    "          .setClusterSize(args.cluster_size) \\\n",
    "          .setNumPS(args.num_ps) \\\n",
    "          .setProtocol(args.protocol) \\\n",
    "          .setTensorboard(args.tensorboard) \\\n",
    "          .setEpochs(args.epochs) \\\n",
    "          .setBatchSize(args.batch_size) \\\n",
    "          .setSteps(args.steps)\n",
    "    model = estimator.fit(df)\n",
    "    \n",
    "else:\n",
    "    model = TFModel(args) \\\n",
    "        .setExportDir(args.export_dir) \\\n",
    "        .setBatchSize(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.inference_mode == 'none':\n",
    "    sys.exit(0)\n",
    "    \n",
    "elif args.inference_mode == 'checkpoint':\n",
    "    model.setModelDir(args.model_dir)                         # load model from checkpoint at args.model_dir\n",
    "    model.setExportDir(None)                                  # don't use a saved_model\n",
    "    model.setInputMapping({'image':'model.X'})                      # map DataFrame 'image' column to the 'x' input tensor\n",
    "    if args.inference_output == 'predictions':\n",
    "        model.setOutputMapping({'prediction':'col_out'})      # map 'prediction' output tensor to output DataFrame 'col_out' column\n",
    "    else:  # args.inference_output == 'features':\n",
    "        model.setOutputMapping({'prediction':'col_out', 'Relu':'col_out2'})   # add 'Relu' output tensor to output DataFrame 'col_out2' column\n",
    "\n",
    "elif args.inference_mode == 'signature':\n",
    "    model.setModelDir(None)                                   # don't use the model checkpoint\n",
    "    model.setExportDir(args.export_dir)                       # load saved_model from args.export_dir\n",
    "    model.setTagSet(tf.saved_model.tag_constants.SERVING)     # using default SERVING tagset\n",
    "    model.setInputMapping({'image':'image'})                  # map DataFrame 'image' column to the 'image' input tensor alias of signature\n",
    "    if args.inference_output == 'predictions':\n",
    "        model.setSignatureDefKey(tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)   # default signature def key, i.e. 'predict'\n",
    "        model.setOutputMapping({'prediction':'col_out'})      # map 'prediction' output tensor alias to output DataFrame 'col_out' column\n",
    "    else:  # args.inference_output == 'features'\n",
    "        model.setSignatureDefKey('featurize')                 # custom signature def key\n",
    "        model.setOutputMapping({'features':'col_out'})        # map 'features' output tensor alias to output DataFrame 'col_out' column\n",
    "\n",
    "else:  \n",
    "    model.setModelDir(None)                                   # don't use the model checkpoint\n",
    "    model.setExportDir(args.export_dir)                       # load saved_model from args.export_dir\n",
    "    model.setTagSet(tf.saved_model.tag_constants.SERVING)     # using default SERVING tagset\n",
    "    model.setInputMapping({'image':'model.X'})                      # map DataFrame 'image' column to the 'x' input tensor\n",
    "    if args.inference_output == 'predictions':\n",
    "        model.setOutputMapping({'prediction': 'col_out'})     # map 'prediction' output tensor to output DataFrame 'col_out' column\n",
    "    else:  # args.inference_output == 'features'\n",
    "        model.setOutputMapping({'prediction': 'col_out', 'Relu': 'col_out2'})   # add 'Relu' output tensor to output DataFrame 'col_out2' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0} ===== Model.transform()\".format(datetime.now().isoformat()))\n",
    "preds = model.transform(df)\n",
    "preds.write.json(args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
